RepeatingTokenStream
int
num
Token
t
RepeatingTokenStream
val
String
t
Token
length
setTermBuffer
val
next
Token
reusableToken
Token
return
num
Token
clone
TokenStream
TestTermdocPerf
addDocs
dir
Directory
ndocs
int
field
String
val
String
maxTF
int
percentDocs
float
Random
random
Random
RepeatingTokenStream
ts
RepeatingTokenStream
val
Analyzer
analyzer
Analyzer
tokenStream
TokenStream
fieldName
String
reader
Reader
if
nextFloat
percentDocs
num
nextInt
maxTF
num
return
ts
Document
doc
Document
add
Field
field
val
NO
NOT_ANALYZED_NO_NORMS
IndexWriter
writer
IndexWriter
dir
analyzer
LIMITED
setMaxBufferedDocs
setMergeFactor
for
forControl
int
i
i
ndocs
i
block
addDocument
doc
optimize
close
doTest
int
iter
int
ndocs
int
maxTF
int
percentDocs
float
Directory
dir
RAMDirectory
long
start
currentTimeMillis
addDocs
dir
ndocs
maxTF
percentDocs
long
end
currentTimeMillis
println
ndocs
end
start
IndexReader
reader
open
dir
TermEnum
tenum
terms
Term
TermDocs
tdocs
termDocs
start
currentTimeMillis
int
ret
for
forControl
int
i
i
iter
i
block
seek
tenum
while
next
block
ret
doc
end
currentTimeMillis
println
iter
end
start
return
ret
testTermDocPerf
LuceneTestCase
