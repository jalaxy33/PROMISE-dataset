package
org
.
apache
.
lucene
.
analysis
;
import
java
.
io
.
IOException
;
import
java
.
io
.
Reader
;
public
abstract
class
CharTokenizer
extends
Tokenizer
{
public
CharTokenizer
(
Reader
input
)
{
super
(
input
)
;
}
private
int
offset
=
0
,
bufferIndex
=
0
,
dataLen
=
0
;
private
static
final
int
MAX_WORD_LEN
=
255
;
private
static
final
int
IO_BUFFER_SIZE
=
4096
;
private
final
char
[
]
ioBuffer
=
new
char
[
IO_BUFFER_SIZE
]
;
protected
abstract
boolean
isTokenChar
(
char
c
)
;
protected
char
normalize
(
char
c
)
{
return
c
;
}
public
final
Token
next
(
final
Token
reusableToken
)
throws
IOException
{
assert
reusableToken
!=
null
;
reusableToken
.
clear
(
)
;
int
length
=
0
;
int
start
=
bufferIndex
;
char
[
]
buffer
=
reusableToken
.
termBuffer
(
)
;
while
(
true
)
{
if
(
bufferIndex
>=
dataLen
)
{
offset
+=
dataLen
;
dataLen
=
input
.
read
(
ioBuffer
)
;
if
(
dataLen
==
-
1
)
{
if
(
length
>
0
)
break
;
else
return
null
;
}
bufferIndex
=
0
;
}
final
char
c
=
ioBuffer
[
bufferIndex
++
]
;
if
(
isTokenChar
(
c
)
)
{
if
(
length
==
0
)
start
=
offset
+
bufferIndex
-
1
;
else
if
(
length
==
buffer
.
length
)
buffer
=
reusableToken
.
resizeTermBuffer
(
1
+
length
)
;
buffer
[
length
++
]
=
normalize
(
c
)
;
if
(
length
==
MAX_WORD_LEN
)
break
;
}
else
if
(
length
>
0
)
break
;
}
reusableToken
.
setTermLength
(
length
)
;
reusableToken
.
setStartOffset
(
start
)
;
reusableToken
.
setEndOffset
(
start
+
length
)
;
return
reusableToken
;
}
public
void
reset
(
Reader
input
)
throws
IOException
{
super
.
reset
(
input
)
;
bufferIndex
=
0
;
offset
=
0
;
dataLen
=
0
;
}
}
