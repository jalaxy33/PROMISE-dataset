package
org
.
apache
.
lucene
.
analysis
;
import
java
.
io
.
IOException
;
import
java
.
io
.
Reader
;
public
abstract
class
CharTokenizer
extends
Tokenizer
{
public
CharTokenizer
(
Reader
input
)
{
super
(
input
)
;
}
private
int
offset
=
0
,
bufferIndex
=
0
,
dataLen
=
0
;
private
static
final
int
MAX_WORD_LEN
=
255
;
private
static
final
int
IO_BUFFER_SIZE
=
1024
;
private
final
char
[
]
buffer
=
new
char
[
MAX_WORD_LEN
]
;
private
final
char
[
]
ioBuffer
=
new
char
[
IO_BUFFER_SIZE
]
;
protected
abstract
boolean
isTokenChar
(
char
c
)
;
protected
char
normalize
(
char
c
)
{
return
c
;
}
public
final
Token
next
(
)
throws
IOException
{
int
length
=
0
;
int
start
=
offset
;
while
(
true
)
{
final
char
c
;
offset
++
;
if
(
bufferIndex
>=
dataLen
)
{
dataLen
=
input
.
read
(
ioBuffer
)
;
bufferIndex
=
0
;
}
;
if
(
dataLen
==
-
1
)
{
if
(
length
>
0
)
break
;
else
return
null
;
}
else
c
=
ioBuffer
[
bufferIndex
++
]
;
if
(
isTokenChar
(
c
)
)
{
if
(
length
==
0
)
start
=
offset
-
1
;
buffer
[
length
++
]
=
normalize
(
c
)
;
if
(
length
==
MAX_WORD_LEN
)
break
;
}
else
if
(
length
>
0
)
break
;
}
return
new
Token
(
new
String
(
buffer
,
0
,
length
)
,
start
,
start
+
length
)
;
}
}
