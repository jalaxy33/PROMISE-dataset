package
org
.
gjt
.
sp
.
jedit
.
syntax
;
import
javax
.
swing
.
text
.
*
;
import
java
.
util
.
*
;
import
org
.
gjt
.
sp
.
jedit
.
*
;
import
org
.
gjt
.
sp
.
util
.
Log
;
public
class
TokenMarker
{
public
static
final
int
MAJOR_ACTIONS
=
0x000000FF
;
public
static
final
int
WHITESPACE
=
1
<<
0
;
public
static
final
int
SPAN
=
1
<<
1
;
public
static
final
int
MARK_PREVIOUS
=
1
<<
2
;
public
static
final
int
MARK_FOLLOWING
=
1
<<
3
;
public
static
final
int
EOL_SPAN
=
1
<<
4
;
public
static
final
int
ACTION_HINTS
=
0x0000FF00
;
public
static
final
int
EXCLUDE_MATCH
=
1
<<
8
;
public
static
final
int
AT_LINE_START
=
1
<<
9
;
public
static
final
int
NO_LINE_BREAK
=
1
<<
10
;
public
static
final
int
NO_WORD_BREAK
=
1
<<
11
;
public
static
final
int
IS_ESCAPE
=
1
<<
12
;
public
static
final
int
DELEGATE
=
1
<<
13
;
public
TokenMarker
(
)
{
ruleSets
=
new
Hashtable
(
64
)
;
}
public
void
addRuleSet
(
String
setName
,
ParserRuleSet
rules
)
{
if
(
rules
==
null
)
return
;
if
(
setName
==
null
)
setName
=
"MAIN"
;
ruleSets
.
put
(
rulePfx
.
concat
(
setName
)
,
rules
)
;
}
public
ParserRuleSet
getMainRuleSet
(
)
{
return
getRuleSet
(
rulePfx
+
"MAIN"
)
;
}
public
ParserRuleSet
getRuleSet
(
String
setName
)
{
ParserRuleSet
rules
;
rules
=
(
ParserRuleSet
)
ruleSets
.
get
(
setName
)
;
if
(
rules
==
null
&&
!
setName
.
startsWith
(
rulePfx
)
)
{
int
delim
=
setName
.
indexOf
(
"::"
)
;
String
modeName
=
setName
.
substring
(
0
,
delim
)
;
Mode
mode
=
jEdit
.
getMode
(
modeName
)
;
if
(
mode
==
null
)
{
Log
.
log
(
Log
.
ERROR
,
TokenMarker
.
class
,
"Unknown edit mode: "
+
modeName
)
;
rules
=
null
;
}
else
{
TokenMarker
marker
=
mode
.
getTokenMarker
(
)
;
rules
=
marker
.
getRuleSet
(
setName
)
;
}
ruleSets
.
put
(
setName
,
rules
)
;
}
if
(
rules
==
null
)
{
Log
.
log
(
Log
.
ERROR
,
this
,
"Unresolved delegate target: "
+
setName
)
;
}
return
rules
;
}
public
String
getName
(
)
{
return
name
;
}
public
void
setName
(
String
name
)
{
if
(
name
==
null
)
throw
new
NullPointerException
(
)
;
this
.
name
=
name
;
rulePfx
=
name
.
concat
(
"::"
)
;
}
public
void
markTokens
(
Buffer
.
LineInfo
prevInfo
,
Buffer
.
LineInfo
info
,
Segment
line
)
{
LineContext
lastContext
=
(
prevInfo
==
null
?
null
:
prevInfo
.
context
)
;
if
(
lastContext
==
null
)
{
lastContext
=
new
LineContext
(
null
,
getRuleSet
(
rulePfx
.
concat
(
"MAIN"
)
)
)
;
}
context
=
info
.
context
;
context
.
parent
=
(
lastContext
.
parent
==
null
?
null
:
(
LineContext
)
lastContext
.
parent
.
clone
(
)
)
;
context
.
inRule
=
lastContext
.
inRule
;
context
.
rules
=
lastContext
.
rules
;
lastOffset
=
lastKeyword
=
line
.
offset
;
lineLength
=
line
.
count
+
line
.
offset
;
int
terminateChar
=
context
.
rules
.
getTerminateChar
(
)
;
int
searchLimit
=
(
terminateChar
>=
0
&&
terminateChar
<
line
.
count
)
?
line
.
offset
+
terminateChar
:
lineLength
;
escaped
=
false
;
boolean
b
;
boolean
tempEscaped
;
Segment
tempPattern
;
ParserRule
rule
;
LineContext
tempContext
;
for
(
pos
=
line
.
offset
;
pos
<
searchLimit
;
pos
++
)
{
if
(
context
.
parent
!=
null
)
{
tempContext
=
context
;
context
=
context
.
parent
;
pattern
.
array
=
context
.
inRule
.
searchChars
;
pattern
.
count
=
context
.
inRule
.
sequenceLengths
[
1
]
;
pattern
.
offset
=
context
.
inRule
.
sequenceLengths
[
0
]
;
b
=
handleRule
(
info
,
line
,
context
.
inRule
)
;
context
=
tempContext
;
if
(
!
b
)
{
if
(
escaped
)
{
escaped
=
false
;
}
else
{
if
(
pos
!=
lastOffset
)
{
if
(
context
.
inRule
==
null
)
{
markKeyword
(
info
,
line
,
lastKeyword
,
pos
)
;
info
.
addToken
(
pos
-
lastOffset
,
context
.
rules
.
getDefault
(
)
)
;
}
else
if
(
(
context
.
inRule
.
action
&
(
NO_LINE_BREAK
|
NO_WORD_BREAK
)
)
==
0
)
{
info
.
addToken
(
pos
-
lastOffset
,
context
.
inRule
.
token
)
;
}
else
{
info
.
addToken
(
pos
-
lastOffset
,
Token
.
INVALID
)
;
}
}
context
=
(
LineContext
)
context
.
parent
;
if
(
(
context
.
inRule
.
action
&
EXCLUDE_MATCH
)
==
EXCLUDE_MATCH
)
{
info
.
addToken
(
pattern
.
count
,
context
.
rules
.
getDefault
(
)
)
;
}
else
{
info
.
addToken
(
pattern
.
count
,
context
.
inRule
.
token
)
;
}
context
.
inRule
=
null
;
lastKeyword
=
lastOffset
=
pos
+
pattern
.
count
;
}
pos
+=
(
pattern
.
count
-
1
)
;
continue
;
}
}
if
(
(
rule
=
context
.
rules
.
getEscapeRule
(
)
)
!=
null
)
{
tempPattern
=
pattern
;
pattern
=
context
.
rules
.
getEscapePattern
(
)
;
tempEscaped
=
escaped
;
b
=
handleRule
(
info
,
line
,
rule
)
;
pattern
=
tempPattern
;
if
(
!
b
)
{
if
(
tempEscaped
)
escaped
=
false
;
continue
;
}
}
rule
=
context
.
inRule
;
if
(
rule
!=
null
&&
(
rule
.
action
&
SPAN
)
==
SPAN
)
{
pattern
.
array
=
rule
.
searchChars
;
pattern
.
count
=
rule
.
sequenceLengths
[
1
]
;
pattern
.
offset
=
rule
.
sequenceLengths
[
0
]
;
if
(
!
handleRule
(
info
,
line
,
rule
)
||
(
rule
.
action
&
SOFT_SPAN
)
==
0
)
{
escaped
=
false
;
continue
;
}
}
rule
=
context
.
rules
.
getRules
(
line
.
array
[
pos
]
)
;
while
(
rule
!=
null
)
{
pattern
.
array
=
rule
.
searchChars
;
if
(
context
.
inRule
==
rule
&&
(
rule
.
action
&
SPAN
)
==
SPAN
)
{
pattern
.
count
=
rule
.
sequenceLengths
[
1
]
;
pattern
.
offset
=
rule
.
sequenceLengths
[
0
]
;
}
else
{
pattern
.
count
=
rule
.
sequenceLengths
[
0
]
;
pattern
.
offset
=
0
;
}
if
(
!
handleRule
(
info
,
line
,
rule
)
)
break
;
rule
=
rule
.
next
;
}
escaped
=
false
;
}
if
(
context
.
inRule
==
null
)
markKeyword
(
info
,
line
,
lastKeyword
,
lineLength
)
;
if
(
lastOffset
!=
lineLength
)
{
if
(
context
.
inRule
==
null
)
{
info
.
addToken
(
lineLength
-
lastOffset
,
context
.
rules
.
getDefault
(
)
)
;
}
else
if
(
(
context
.
inRule
.
action
&
SPAN
)
==
SPAN
&&
(
context
.
inRule
.
action
&
(
NO_LINE_BREAK
|
NO_WORD_BREAK
)
)
!=
0
)
{
info
.
addToken
(
lineLength
-
lastOffset
,
Token
.
INVALID
)
;
context
.
inRule
=
null
;
}
else
{
info
.
addToken
(
lineLength
-
lastOffset
,
context
.
inRule
.
token
)
;
if
(
(
context
.
inRule
.
action
&
MARK_FOLLOWING
)
==
MARK_FOLLOWING
)
{
context
.
inRule
=
null
;
}
}
}
info
.
context
=
context
;
}
private
static
final
int
SOFT_SPAN
=
MARK_FOLLOWING
|
NO_WORD_BREAK
;
private
String
name
;
private
String
rulePfx
;
private
Hashtable
ruleSets
;
private
LineContext
context
;
private
Segment
pattern
=
new
Segment
(
new
char
[
0
]
,
0
,
0
)
;
private
int
lastOffset
;
private
int
lastKeyword
;
private
int
lineLength
;
private
int
pos
;
private
boolean
escaped
;
private
boolean
handleRule
(
Buffer
.
LineInfo
info
,
Segment
line
,
ParserRule
checkRule
)
{
if
(
pattern
.
count
==
0
)
return
true
;
if
(
lineLength
-
pos
<
pattern
.
count
)
return
true
;
char
a
,
b
;
for
(
int
k
=
0
;
k
<
pattern
.
count
;
k
++
)
{
a
=
pattern
.
array
[
pattern
.
offset
+
k
]
;
b
=
line
.
array
[
pos
+
k
]
;
if
(
!
(
a
==
b
||
context
.
rules
.
getIgnoreCase
(
)
&&
(
Character
.
toLowerCase
(
a
)
==
b
||
a
==
Character
.
toLowerCase
(
b
)
)
)
)
return
true
;
}
if
(
escaped
)
{
pos
+=
pattern
.
count
-
1
;
return
false
;
}
else
if
(
(
checkRule
.
action
&
IS_ESCAPE
)
==
IS_ESCAPE
)
{
escaped
=
true
;
pos
+=
pattern
.
count
-
1
;
return
false
;
}
if
(
context
.
inRule
!=
checkRule
&&
context
.
inRule
!=
null
&&
(
context
.
inRule
.
action
&
SOFT_SPAN
)
!=
0
)
{
if
(
(
context
.
inRule
.
action
&
NO_WORD_BREAK
)
==
NO_WORD_BREAK
)
{
info
.
addToken
(
pos
-
lastOffset
,
Token
.
INVALID
)
;
}
else
{
info
.
addToken
(
pos
-
lastOffset
,
context
.
inRule
.
token
)
;
}
lastOffset
=
lastKeyword
=
pos
;
context
.
inRule
=
null
;
}
if
(
context
.
inRule
==
null
)
{
if
(
(
checkRule
.
action
&
AT_LINE_START
)
==
AT_LINE_START
)
{
if
(
(
(
(
checkRule
.
action
&
MARK_PREVIOUS
)
!=
0
)
?
lastKeyword
:
pos
)
!=
line
.
offset
)
{
return
true
;
}
}
markKeyword
(
info
,
line
,
lastKeyword
,
pos
)
;
if
(
(
checkRule
.
action
&
MARK_PREVIOUS
)
!=
MARK_PREVIOUS
)
{
lastKeyword
=
pos
+
pattern
.
count
;
if
(
(
checkRule
.
action
&
WHITESPACE
)
==
WHITESPACE
)
{
return
false
;
}
if
(
lastOffset
<
pos
)
{
info
.
addToken
(
pos
-
lastOffset
,
context
.
rules
.
getDefault
(
)
)
;
}
}
switch
(
checkRule
.
action
&
MAJOR_ACTIONS
)
{
case
0
:
info
.
addToken
(
pattern
.
count
,
checkRule
.
token
)
;
lastOffset
=
pos
+
pattern
.
count
;
break
;
case
SPAN
:
context
.
inRule
=
checkRule
;
if
(
(
checkRule
.
action
&
DELEGATE
)
!=
DELEGATE
)
{
if
(
(
checkRule
.
action
&
EXCLUDE_MATCH
)
==
EXCLUDE_MATCH
)
{
info
.
addToken
(
pattern
.
count
,
context
.
rules
.
getDefault
(
)
)
;
lastOffset
=
pos
+
pattern
.
count
;
}
else
{
lastOffset
=
pos
;
}
}
else
{
String
setName
=
new
String
(
checkRule
.
searchChars
,
checkRule
.
sequenceLengths
[
0
]
+
checkRule
.
sequenceLengths
[
1
]
,
checkRule
.
sequenceLengths
[
2
]
)
;
ParserRuleSet
delegateSet
=
getRuleSet
(
setName
)
;
if
(
delegateSet
!=
null
)
{
if
(
(
checkRule
.
action
&
EXCLUDE_MATCH
)
==
EXCLUDE_MATCH
)
{
info
.
addToken
(
pattern
.
count
,
context
.
rules
.
getDefault
(
)
)
;
}
else
{
info
.
addToken
(
pattern
.
count
,
checkRule
.
token
)
;
}
lastOffset
=
pos
+
pattern
.
count
;
context
=
new
LineContext
(
delegateSet
,
context
)
;
}
}
break
;
case
EOL_SPAN
:
if
(
(
checkRule
.
action
&
EXCLUDE_MATCH
)
==
EXCLUDE_MATCH
)
{
info
.
addToken
(
pattern
.
count
,
context
.
rules
.
getDefault
(
)
)
;
info
.
addToken
(
lineLength
-
(
pos
+
pattern
.
count
)
,
checkRule
.
token
)
;
}
else
{
info
.
addToken
(
lineLength
-
pos
,
checkRule
.
token
)
;
}
lastOffset
=
lineLength
;
lastKeyword
=
lineLength
;
pos
=
lineLength
;
return
false
;
case
MARK_PREVIOUS
:
if
(
lastKeyword
>
lastOffset
)
{
info
.
addToken
(
lastKeyword
-
lastOffset
,
context
.
rules
.
getDefault
(
)
)
;
lastOffset
=
lastKeyword
;
}
if
(
(
checkRule
.
action
&
EXCLUDE_MATCH
)
==
EXCLUDE_MATCH
)
{
info
.
addToken
(
pos
-
lastOffset
,
checkRule
.
token
)
;
info
.
addToken
(
pattern
.
count
,
context
.
rules
.
getDefault
(
)
)
;
}
else
{
info
.
addToken
(
pos
-
lastOffset
+
pattern
.
count
,
checkRule
.
token
)
;
}
lastOffset
=
pos
+
pattern
.
count
;
break
;
case
MARK_FOLLOWING
:
context
.
inRule
=
checkRule
;
if
(
(
checkRule
.
action
&
EXCLUDE_MATCH
)
==
EXCLUDE_MATCH
)
{
info
.
addToken
(
pattern
.
count
,
context
.
rules
.
getDefault
(
)
)
;
lastOffset
=
pos
+
pattern
.
count
;
}
else
{
lastOffset
=
pos
;
}
break
;
default
:
throw
new
InternalError
(
"Unhandled major action"
)
;
}
lastKeyword
=
lastOffset
;
pos
+=
(
pattern
.
count
-
1
)
;
return
false
;
}
else
if
(
(
checkRule
.
action
&
SPAN
)
==
SPAN
)
{
if
(
(
checkRule
.
action
&
DELEGATE
)
!=
DELEGATE
)
{
context
.
inRule
=
null
;
if
(
(
checkRule
.
action
&
EXCLUDE_MATCH
)
==
EXCLUDE_MATCH
)
{
info
.
addToken
(
pos
-
lastOffset
,
checkRule
.
token
)
;
info
.
addToken
(
pattern
.
count
,
context
.
rules
.
getDefault
(
)
)
;
}
else
{
info
.
addToken
(
(
pos
+
pattern
.
count
)
-
lastOffset
,
checkRule
.
token
)
;
}
lastKeyword
=
lastOffset
=
pos
+
pattern
.
count
;
pos
+=
(
pattern
.
count
-
1
)
;
}
return
false
;
}
return
true
;
}
private
void
markKeyword
(
Buffer
.
LineInfo
info
,
Segment
line
,
int
start
,
int
end
)
{
KeywordMap
keywords
=
context
.
rules
.
getKeywords
(
)
;
int
len
=
end
-
start
;
if
(
context
.
rules
.
getHighlightDigits
(
)
)
{
boolean
digit
=
true
;
char
[
]
array
=
line
.
array
;
boolean
octal
=
false
;
boolean
hex
=
false
;
boolean
seenSomeDigits
=
false
;
loop
:
for
(
int
i
=
0
;
i
<
len
;
i
++
)
{
char
ch
=
array
[
start
+
i
]
;
switch
(
ch
)
{
case
'0'
:
if
(
i
==
0
)
octal
=
true
;
seenSomeDigits
=
true
;
continue
loop
;
case
'1'
:
case
'2'
:
case
'3'
:
case
'4'
:
case
'5'
:
case
'6'
:
case
'7'
:
case
'8'
:
case
'9'
:
seenSomeDigits
=
true
;
continue
loop
;
case
'x'
:
case
'X'
:
if
(
octal
&&
i
==
1
)
{
hex
=
true
;
continue
loop
;
}
else
break
;
case
'd'
:
case
'D'
:
if
(
hex
)
continue
loop
;
else
break
;
case
'f'
:
case
'F'
:
if
(
hex
||
seenSomeDigits
)
continue
loop
;
else
break
;
case
'l'
:
case
'L'
:
if
(
seenSomeDigits
)
continue
loop
;
else
break
;
case
'e'
:
case
'E'
:
if
(
seenSomeDigits
)
continue
loop
;
else
break
;
case
'a'
:
case
'A'
:
case
'b'
:
case
'B'
:
case
'c'
:
case
'C'
:
if
(
hex
)
continue
loop
;
else
break
;
case
'.'
:
case
'-'
:
continue
loop
;
default
:
break
;
}
digit
=
false
;
break
loop
;
}
if
(
digit
)
{
if
(
start
!=
lastOffset
)
{
info
.
addToken
(
start
-
lastOffset
,
context
.
rules
.
getDefault
(
)
)
;
}
info
.
addToken
(
len
,
Token
.
DIGIT
)
;
lastKeyword
=
lastOffset
=
end
;
return
;
}
}
if
(
keywords
!=
null
)
{
byte
id
=
keywords
.
lookup
(
line
,
start
,
len
)
;
if
(
id
!=
Token
.
NULL
)
{
if
(
start
!=
lastOffset
)
{
info
.
addToken
(
start
-
lastOffset
,
context
.
rules
.
getDefault
(
)
)
;
}
info
.
addToken
(
len
,
id
)
;
lastKeyword
=
lastOffset
=
end
;
}
}
}
public
static
class
LineContext
{
public
LineContext
parent
;
public
ParserRule
inRule
;
public
ParserRuleSet
rules
;
public
LineContext
(
ParserRule
r
,
ParserRuleSet
rs
)
{
inRule
=
r
;
rules
=
rs
;
}
public
LineContext
(
ParserRuleSet
rs
,
LineContext
lc
)
{
rules
=
rs
;
parent
=
(
lc
==
null
?
null
:
(
LineContext
)
lc
.
clone
(
)
)
;
}
public
LineContext
(
ParserRule
r
)
{
inRule
=
r
;
}
public
LineContext
(
)
{
}
public
Object
clone
(
)
{
LineContext
lc
=
new
LineContext
(
)
;
lc
.
inRule
=
inRule
;
lc
.
rules
=
rules
;
lc
.
parent
=
(
parent
==
null
)
?
null
:
(
LineContext
)
parent
.
clone
(
)
;
return
lc
;
}
}
}
